from urllib.parse import urljoin
from bs4 import BeautifulSoup
import requests

from parsers.list_page_parser import parse_chapter_list_from_list_page
from parsers.single_page_parser import parse_chapter_list_from_single_page
from sheets.story_sheet import StorySheet
from sheets.task_sheet import TaskSheet


def dispatch_tasks(spreadsheet_id: str):
    # Kh·ªüi t·∫°o sheet
    story_sheet = StorySheet(spreadsheet_id)
    task_sheet = TaskSheet(spreadsheet_id)

    # L·∫•y c√°c truy·ªán c√≥ tr·∫°ng th√°i NEW
    new_stories = story_sheet.get_new_stories()

    for story in new_stories:
        story_id = story["story_id"]
        url_list_page = story["url_list_page"]
        quantity_per_task = int(story.get("quantity_per_task", 10))
        parser_type = story.get("parser_type", "list_page")  # M·∫∑c ƒë·ªãnh l√† list_page

        print(f"\nüöÄ ƒêang x·ª≠ l√Ω truy·ªán: {story_id} - {story['title']}")
        print(f"URL danh s√°ch ch∆∞∆°ng: {url_list_page}")
        print(f"Parser type: {parser_type}")

        try:
            if parser_type == "list_page":
                # B1: L·∫•y to√†n b·ªô c√°c trang ch·ª©a danh s√°ch ch∆∞∆°ng
                headers = {
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36"
                }
                resp = requests.get(url_list_page, headers=headers, timeout=10)
                resp.raise_for_status()

                soup = BeautifulSoup(resp.text, "html.parser")
                select = soup.find("select", id="indexselect")
                if not select:
                    raise Exception("Kh√¥ng t√¨m th·∫•y <select id='indexselect'> trong trang danh s√°ch ch∆∞∆°ng.")

                page_urls = [urljoin(url_list_page, opt.get("value")) for opt in select.find_all("option")]

                print(f"üîç T√¨m th·∫•y {len(page_urls)} trang danh s√°ch ch∆∞∆°ng.")

                all_chapters = []
                for page_url in page_urls:
                    chapter_list = parse_chapter_list_from_list_page(page_url)
                    all_chapters.extend(chapter_list)

            elif parser_type == "single_page":
                # Ch·ªâ c·∫ßn parse tr·ª±c ti·∫øp t·ª´ 1 trang
                all_chapters = parse_chapter_list_from_single_page(url_list_page)

            else:
                raise Exception(f"parser_type '{parser_type}' kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£.")

            print(f"üìö T·ªïng s·ªë ch∆∞∆°ng thu ƒë∆∞·ª£c: {len(all_chapters)}")

            # B2: Chia th√†nh c√°c task
            tasks = []
            for i in range(0, len(all_chapters), quantity_per_task):
                chapter_group = all_chapters[i:i+quantity_per_task]
                task = {
                    "task_id": f"{story_id}_part{i//quantity_per_task + 1}",
                    "story_id": story_id,
                    "chapter_from": i + 1,
                    "chapter_to": i + len(chapter_group),
                    "url_chapters": [ch["url"] for ch in chapter_group],
                    "status": "PENDING",
                    "translated": False,
                    "css_title": story["css_title"],
                    "css_content": story["css_content"],
                    "css_next": story["css_next"],
                    "doc_url": "",
                    "audio_urls": [],
                    "video_path": "",
                    "summary": ""
                }
                tasks.append(task)
            print(tasks)
            # # B3: Ghi c√°c task v√†o sheet
            # task_sheet.append_tasks(tasks)
            #
            # # B4: C·∫≠p nh·∫≠t tr·∫°ng th√°i truy·ªán
            # story_sheet.update_story_status(story_id, "DISPATCHED")

            print(f"‚úÖ ƒê√£ chia {len(tasks)} task cho truy·ªán {story_id}")

        except Exception as e:
            print(f"‚ùå L·ªói khi x·ª≠ l√Ω truy·ªán {story_id}: {e}")


if __name__ == "__main__":
    # V√≠ d·ª• ch·∫°y
    spreadsheet_id = "YOUR_SPREADSHEET_ID_HERE"
    dispatch_tasks(spreadsheet_id)
